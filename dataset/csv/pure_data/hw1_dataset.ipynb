{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "李宏毅.作业一数据集处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path = './covid.train.csv'\n",
    "tt_path = './covid.test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tr_path, 'r') as fp:\n",
    "    raw_data = list(csv.reader(fp))\n",
    "    raw_data = np.array(raw_data[1:])[:, 1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.1518381, 19.586492 , 25.6489069, 25.6791006, 26.0605436,\n",
       "       21.2420632, 21.2802696, 21.5038315,  0.81461  ,  0.8389952,\n",
       "        0.8978015,  0.7713562,  0.8077665,  0.8878931])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = [75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77]\n",
    "raw_data[0][feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.1518381, 19.586492 , 25.6489069, 25.6791006, 26.0605436,\n",
       "       21.2420632, 21.2802696, 21.5038315,  0.81461  ,  0.8389952,\n",
       "        0.8978015,  0.7713562,  0.8077665,  0.8878931])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0,feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=True):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        \n",
    "        if not target_only:\n",
    "            feats = list(range(93))\n",
    "            # feats = list(range(1, 40)) + [57, 75]\n",
    "        else:\n",
    "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
    "            # feats = list(range(1, 41)) + [57, 75]\n",
    "            feats = [75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77] #上面挑选的最优特征\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "            \n",
    "            # Splitting training data into train & dev sets\n",
    "            # 在确定参数后，使用所有数据进行训练，即训练集=验证集\n",
    "            if mode == 'train':\n",
    "                #indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "                indices = [i for i in range(len(data))]\n",
    "            elif mode == 'dev':\n",
    "                #indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "                indices = [i for i in range(len(data))]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features (you may remove this part to see what will happen)\n",
    "        # 只在 target_only = False 时进行归一化\n",
    "        self.data[:, 40:] = \\\n",
    "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
    "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2700 samples found, each dim = 14)\n"
     ]
    }
   ],
   "source": [
    "tr_dataset = COVID19Dataset(tr_path, mode='train', target_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([20.1518, 19.5865, 25.6489, 25.6791, 26.0605, 21.2421, 21.2803, 21.5038,\n",
       "          0.8146,  0.8390,  0.8978,  0.7714,  0.8078,  0.8879]),\n",
       " tensor(20.7049))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2700 samples found, each dim = 93)\n"
     ]
    }
   ],
   "source": [
    "tr_dataset_all = COVID19Dataset(tr_path, mode='train', target_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.4211, -0.5778, -0.4172, -0.3648, -0.9364,  1.3419,  0.9772,  1.7371,\n",
       "          1.2597,  1.2648,  1.4035, -0.6428, -1.1475, -0.6367, -0.8175, -1.7962,\n",
       "         -0.2355,  0.4302, -0.3703, -0.4991, -0.4239, -0.3698, -1.0681,  1.3591,\n",
       "          1.0116,  1.7946,  1.2462,  1.2317,  1.3125, -0.6879, -1.2323, -0.6249,\n",
       "         -0.9886, -1.8433, -0.1755,  0.4962, -0.2384, -0.3176, -0.3914, -0.3525,\n",
       "         -1.0000,  1.2458,  0.9802,  1.6167,  1.2800,  1.1052,  1.2577, -0.7436,\n",
       "         -1.1814, -0.5957, -0.9383, -1.7432, -0.1843]),\n",
       " tensor(20.7049))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_dataset_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False,drop_last=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=drop_last,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2700 samples found, each dim = 14)\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([140, 14]) torch.Size([140])\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(tr_path, 'train', 256, target_only=True)\n",
    "l = 0\n",
    "for x, y in tr_set:\n",
    "    print(x.shape, y.shape)\n",
    "    l += x.shape[0]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2700 samples found, each dim = 14)\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "torch.Size([256, 14]) torch.Size([256])\n",
      "2560\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(tr_path, 'train', 256, target_only=True,drop_last=True)\n",
    "l = 0\n",
    "for x, y in tr_set:\n",
    "    print(x.shape, y.shape)\n",
    "    l += x.shape[0]\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e1e609ed4275b16681bc4abde79d07778f26b9708257cdaa3e43b60c63d82f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
